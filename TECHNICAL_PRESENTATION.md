# GAIA Planning: Technical Stack & Algorithm Documentation

**Healthcare Resource Allocation for Malawi**  
*A Data-Driven Approach to Equitable Healthcare Access*

---

## ðŸŽ¯ Project Overview

**Problem:** In rural Malawi, people die due to lack of access to healthcare facilities. GAIA (Oakland, CA) deploys mobile health clinics to reach underserved populations, but needs data-driven tools to optimize resource allocation.

**Solution:** An interactive geospatial analytics platform that:
- Visualizes population density and healthcare facility distribution
- Analyzes coverage gaps and identifies underserved populations
- Plans optimal mobile clinic deployment routes
- Provides district-level analysis for resource allocation

---

## ðŸ“Š 1. DATA AVAILABLE

### 1.1 Population Data
**Source:** Meta Data for Good - High Resolution Population Density Maps (2020)

**Coverage:** ~1.5GB of granular population data
- **7 demographic datasets** with ~300,000-400,000 data points each
- **Spatial resolution:** ~100m grid cells across entire country
- **Demographics:**
  - General population (`mwi_general_2020.csv`)
  - Women (`mwi_women_2020.csv`)
  - Men (`mwi_men_2020.csv`)
  - Children under 5 (`mwi_children_under_five_2020.csv`)
  - Youth 15-24 (`mwi_youth_15_24_2020.csv`)
  - Elderly 60+ (`mwi_elderly_60_plus_2020.csv`)
  - Women of reproductive age 15-49 (`mwi_women_of_reproductive_age_15_49_2020.csv`)

**Data Points Per Row:**
- `latitude`, `longitude`: Precise geographic coordinates
- `mwi_<demographic>_2020`: Population density estimate for that grid cell

### 1.2 Healthcare Facilities
**Source:** Malawi Health Facility Registry (MHFR)

**Facilities:** ~1,400 registered healthcare facilities
- **Types:** Hospitals, Health Centres, Clinics, Dispensaries
- **Status:** Functional, Non-functional, Under construction
- **Ownership:** Government, CHAM (Christian Health Association), Private
- **Metadata:**
  - GPS coordinates (latitude, longitude)
  - Facility name and code
  - District assignment
  - Operational status

### 1.3 GAIA Mobile Clinics
**Source:** GAIA Mobile Health Clinic GPS logs

**Data:** ~50+ clinic stop locations with GPS coordinates
- Actual field deployment locations
- Used for validation and comparison with planned routes

### 1.4 Administrative Boundaries
**Source:** geoBoundaries (Open-source political boundaries)

**Hierarchy:**
- **Country level:** Malawi national boundary (GeoJSON)
- **Level 2 (Districts):** 28 administrative districts (GeoJSON)
- **Level 3 (Traditional Authorities):** Sub-district boundaries (GeoJSON)

**Used for:**
- Spatial filtering of population data
- District-level aggregation and analysis
- Choropleth visualization

---

## ðŸ”„ 2. DATA TRANSFORMATIONS

### 2.1 Data Loading & Validation

```python
# GPS Coordinate Parsing
# Input: "lat lon elevation accuracy"
# Output: (lat, lon) tuple

def parse_gps_coordinates(gps_string):
    parts = str(gps_string).strip().split()
    lat, lon = float(parts[0]), float(parts[1])
    return lat, lon
```

**Transformations:**
- Parse GPS string format to numeric coordinates
- Validate coordinate ranges (-90 to 90 for lat, -180 to 180 for lon)
- Filter out zero, null, or invalid coordinates
- Remove facilities without type classification

### 2.2 Facility Type Normalization

```python
# Consolidate similar facility types
# Hospital + District Hospital + Central Hospital â†’ "Hospital"
# Health Centre + Health Post â†’ "Health Centre"

def normalize_facility_type(facility_type):
    if facility_type in ["Hospital", "District Hospital", "Central Hospital"]:
        return "Hospital"
    if facility_type in ["Health Centre", "Health Post"]:
        return "Health Centre"
    return facility_type
```

**Purpose:** Standardize facility classifications for consistent analysis and filtering

### 2.3 Geographic Filtering

**Country Boundary Filtering:**
```python
# Remove population points outside Malawi borders
# Uses vectorized geopandas operations
def filter_points_in_country(df, lat_col, lon_col):
    country_gdf = gpd.read_file('boundaries/malawi_country.geojson')
    country_boundary = country_gdf.unary_union
    
    geometry = gpd.points_from_xy(df[lon_col], df[lat_col])
    points_gdf = gpd.GeoDataFrame(df, geometry=geometry)
    
    mask = points_gdf.within(country_boundary)
    return df[mask]
```

**Impact:** Reduces dataset by ~5-10% by removing erroneous coordinates outside country

### 2.4 Spatial District Assignment

**Algorithm:** R-tree indexed spatial join (GeoPandas)
```python
def assign_districts_to_dataframe(df, lat_col, lon_col):
    # Load district boundaries with spatial index
    districts_gdf = gpd.read_file('malawi_districts.geojson')
    
    # Convert points to GeoDataFrame
    geometry = gpd.points_from_xy(df[lon_col], df[lat_col])
    points_gdf = gpd.GeoDataFrame(df, geometry=geometry)
    
    # Spatial join using R-tree (10-100x faster than point-in-polygon)
    joined = gpd.sjoin(points_gdf, districts_gdf, 
                       how='left', predicate='within')
    
    return joined
```

**Performance:** ~5-30 seconds for 50,000 points (vs. 2-5 minutes with naive approach)

### 2.5 Data Sampling for Visualization

**Stratified Sampling:**
```python
def sample_for_visualization(df, sample_size=50000):
    # Reduces data for browser/websocket limits
    # While preserving spatial distribution
    if len(df) <= sample_size:
        return df
    return df.sample(n=sample_size, random_state=42)
```

**Purpose:** 
- Full dataset (400K points) used for all metrics calculations
- Sampled dataset (50K points) used only for map rendering
- Maintains accuracy while avoiding browser memory limits

### 2.6 Coordinate Conversion

**Degrees to Radians:**
```python
# Required for haversine distance calculations on sphere
coords_rad = np.deg2rad(coords_deg)
```

**Haversine Distance Formula:**
```python
def haversine_distance_km(lat1, lon1, lat2, lon2):
    EARTH_RADIUS_KM = 6371.0088
    
    lat1_rad, lon1_rad = np.radians([lat1, lon1])
    lat2_rad, lon2_rad = np.radians([lat2, lon2])
    
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    
    a = (np.sin(dlat/2)**2 + 
         np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2)
    c = 2 * np.arcsin(np.sqrt(a))
    
    return c * EARTH_RADIUS_KM
```

### 2.7 Choropleth Aggregation

**Population aggregation by sub-district:**
```python
def aggregate_population_by_subdistrict(population_df, subdistrict_geojson, pop_column):
    # Convert to GeoDataFrame for efficient spatial ops
    gdf_pop = GeoDataFrame(
        population_df,
        geometry=points_from_xy(population_df['longitude'], 
                               population_df['latitude'])
    )
    
    for feature in subdistrict_geojson['features']:
        polygon = shape(feature['geometry'])
        
        # Vectorized point-in-polygon test
        mask = gdf_pop.geometry.within(polygon)
        points_in_region = gdf_pop[mask]
        
        # Aggregate population
        feature['properties']['population'] = points_in_region[pop_column].sum()
    
    return result_geojson
```

---

## ðŸ—ï¸ 3. DATA STRUCTURES

### 3.1 Core Data Structures

#### **BallTree (Spatial Index)**
```python
from sklearn.neighbors import BallTree

# O(log n) nearest neighbor queries
coords_rad = np.deg2rad(facilities[["lat", "lon"]].to_numpy())
tree = BallTree(coords_rad, metric="haversine")

# Query: Find nearest facility for each population point
distances, indices = tree.query(population_coords_rad, k=1)
```

**Properties:**
- **Structure:** Binary tree optimized for ball-shaped regions on sphere
- **Metric:** Haversine (great-circle distance)
- **Complexity:** 
  - Build: O(n log n)
  - Query: O(log n) per point
  - Radius query: O(log n + k) where k = points within radius

**Use Cases:**
- Coverage calculation (nearest facility distance)
- Overlap analysis (count facilities within radius)
- Gap identification (population points far from facilities)

#### **GeoDataFrame (Spatial Operations)**
```python
import geopandas as gpd
from shapely.geometry import Point, shape

gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(lon, lat))
```

**Properties:**
- Extends pandas DataFrame with geometry column
- Built-in spatial operations: `within`, `contains`, `intersects`
- **R-tree spatial index** for fast spatial joins
- CRS (Coordinate Reference System) management

**Operations Used:**
- `sjoin` - Spatial join (district assignment)
- `within` - Point-in-polygon tests (boundary filtering)
- `unary_union` - Merge multiple polygons (country boundary)

#### **NumPy Arrays (Vectorized Computation)**
```python
# Haversine calculation for 400K points
dlat = lat2_rad - lat1_rad  # Vectorized subtraction
dlon = lon2_rad - lon1_rad

a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2
distances = 2 * np.arcsin(np.sqrt(a)) * EARTH_RADIUS_KM
```

**Benefits:**
- **10-100x faster** than Python loops
- Memory-efficient operations on large arrays
- Parallel execution on modern CPUs (SIMD)

### 3.2 Caching Architecture

#### **Streamlit Cache Decorators**
```python
@st.cache_data(persist="disk", show_spinner=False, max_entries=20)
def load_population_data(dataset_name):
    # Cached on disk, survives app restarts
    cache_file = f"data/.cache/mwi_{dataset_name}_2020_filtered.parquet"
    
    if os.path.exists(cache_file):
        return pd.read_parquet(cache_file)  # Instant load
    
    # Compute and save
    df = compute_filtered_data(dataset_name)
    df.to_parquet(cache_file)
    return df
```

**Cache Layers:**
1. **Memory cache** - Function results in RAM
2. **Disk cache** - Parquet files for preprocessed data
3. **Session cache** - Per-user state management

**Performance Impact:**
- First load: 5-10 seconds (filter + district assignment)
- Subsequent loads: <1 second (parquet read)
- Across restarts: Instant (disk-persisted cache)

### 3.3 GeoJSON Structure

```json
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "geometry": {
        "type": "Polygon",
        "coordinates": [[[lon, lat], [lon, lat], ...]]
      },
      "properties": {
        "shapeName": "Chikwawa",
        "population": 547890,
        "fill_color": [128, 203, 196, 180]
      }
    }
  ]
}
```

**Used for:**
- District boundaries (GeoJsonLayer in PyDeck)
- Choropleth maps (colored by population density)
- Custom polygon markers (hospital icons)

---

## ðŸ§® 4. ALGORITHMS

### 4.1 Coverage Analysis Algorithm

**Problem:** Calculate what % of population is within service radius of facilities

**Algorithm:**
```python
def calculate_coverage_metrics(population_df, facilities_df, 
                               pop_column, service_radius_km=5.0):
    EARTH_RADIUS_KM = 6371.0088
    
    # 1. Build spatial index (O(n log n))
    coords_rad = np.deg2rad(facilities_df[["latitude", "longitude"]])
    tree = BallTree(coords_rad, metric="haversine")
    
    # 2. Query nearest facility for each population point (O(m log n))
    pop_coords_rad = np.deg2rad(population_df[["latitude", "longitude"]])
    dist_rad, _ = tree.query(pop_coords_rad, k=1)
    dist_km = dist_rad.ravel() * EARTH_RADIUS_KM
    
    # 3. Calculate coverage (O(m))
    service_radius_rad = service_radius_km / EARTH_RADIUS_KM
    covered_mask = dist_rad.ravel() <= service_radius_rad
    
    population = population_df[pop_column].to_numpy()
    total_population = population.sum()
    covered_population = population[covered_mask].sum()
    
    # 4. Calculate statistics
    coverage_pct = (covered_population / total_population * 100)
    p50 = np.percentile(dist_km, 50)  # Median distance
    p75 = np.percentile(dist_km, 75)
    p95 = np.percentile(dist_km, 95)
    
    return {
        'total_population': total_population,
        'covered_population': covered_population,
        'coverage_pct': coverage_pct,
        'p50_distance_km': p50,
        'p75_distance_km': p75,
        'p95_distance_km': p95
    }
```

**Complexity:**
- **Time:** O(n log n + m log n) where n = facilities, m = population points
- **Space:** O(n + m)

**Key Insight:** BallTree reduces naive O(nÂ·m) brute-force to O(m log n)

### 4.2 Overlap Analysis Algorithm

**Problem:** Identify facilities with redundant coverage (>95% overlap with others)

**Algorithm:**
```python
def compute_overlap_analysis(population_df, facilities_df, service_radius_km):
    # 1. Build spatial index
    tree = BallTree(coords_rad, metric="haversine")
    service_radius_rad = service_radius_km / EARTH_RADIUS_KM
    
    # 2. For each population point, find ALL facilities within radius
    indices_list = tree.query_radius(pop_coords_rad, r=service_radius_rad)
    
    # 3. Count coverage
    facility_coverage = defaultdict(float)      # Total coverage
    facility_unique_coverage = defaultdict(float)  # Unique coverage
    
    for indices, pop in zip(indices_list, population):
        n_facilities = len(indices)
        
        for facility_idx in indices:
            facility_coverage[facility_idx] += pop
        
        # If only 1 facility covers this point, it's unique coverage
        if n_facilities == 1:
            facility_unique_coverage[indices[0]] += pop
    
    # 4. Calculate redundancy
    for facility_id in facilities:
        total = facility_coverage[facility_id]
        unique = facility_unique_coverage[facility_id]
        redundancy_pct = ((total - unique) / total * 100) if total > 0 else 0
```

**Complexity:**
- **Time:** O(n log n + mÂ·kÂ·log n) where k = avg facilities per population point
- **Space:** O(n + m)

**Output:**
- Redundant facilities (>95% overlap) â†’ candidates for consolidation
- Critical facilities (high unique coverage) â†’ essential, must preserve

### 4.3 Gap Identification Algorithm

**Problem:** Find underserved populations (>10km from any facility)

**Algorithm:**
```python
def find_coverage_gaps(pop_df, facilities_df, max_distance_km=10.0):
    # 1. Build spatial index
    tree = BallTree(coords_rad, metric="haversine")
    max_distance_rad = max_distance_km / EARTH_RADIUS_KM
    
    # 2. Find nearest facility distance for each point
    dist_rad, _ = tree.query(pop_coords_rad, k=1)
    dist_km = dist_rad.ravel() * EARTH_RADIUS_KM
    
    # 3. Filter to gaps
    gap_mask = dist_rad.ravel() > max_distance_rad
    gaps_df = pop_df[gap_mask].copy()
    gaps_df['distance_to_nearest_km'] = dist_km[gap_mask]
    
    return gaps_df
```

**Complexity:** O(n log n + m log n)

### 4.4 Mobile Clinic Route Planning Algorithm

**Problem:** Plan optimal mobile clinic stops from hospital bases to maximize coverage of underserved populations

**Constraints:**
- Deploy from hospitals (infrastructure base)
- Max travel distance: 30km (1 hour off-road)
- 5 stops per crew (Monday-Friday schedule)
- Service radius: 5km per stop
- Minimize overlap with existing facilities

**Algorithm: Hospital-Constrained Greedy Max-Coverage**

```python
def plan_mobile_clinic_stops(pop_df, hospital_df, existing_gaia, num_crews):
    # 1. Build coverage tree from fixed facilities + existing GAIA stops
    coverage_tree = BallTree(existing_sources, metric="haversine")
    service_radius_rad = SERVICE_RADIUS_KM / EARTH_RADIUS_KM
    
    # 2. Identify uncovered population points (gaps)
    dist_rad, _ = coverage_tree.query(pop_coords_rad, k=1)
    gap_mask = dist_rad.ravel() > service_radius_rad
    gap_points = pop_df[gap_mask]
    
    # 3. Greedy assignment per crew
    for crew_idx in range(num_crews):
        best_hospital = None
        best_plan = None
        best_gain = 0
        
        for hospital in hospital_df.itertuples():
            # 3a. Filter gap points within 30km of hospital
            nearby = filter_by_distance(gap_points, hospital, MAX_TRAVEL_DISTANCE_KM)
            
            # 3b. Greedy max-coverage: pick up to 5 stops
            plan = []
            remaining = nearby.copy()
            for _ in range(STOPS_PER_CREW):
                hotspot = remaining.nlargest(1, pop_column)
                covered = remove_within_radius(remaining, hotspot, SERVICE_RADIUS_KM)
                plan.append(summarize(hotspot, covered))
            
            gain = sum(stop['population'] for stop in plan)
            if gain > best_gain:
                best_gain = gain
                best_plan = plan
                best_hospital = hospital
        
        if best_plan:
            yield best_hospital, best_plan
            gap_points = gap_points.drop(best_plan.covered_indices)
        stops_tree = BallTree(selected_coords_rad, metric='haversine')
        covered_mask = stops_tree.query(gap_coords_rad, k=1)[0].ravel() <= service_radius_rad
        gap_points = gap_points[~covered_mask]
    
    return all_proposed_stops
```

**Algorithm Breakdown:**

**Step 1: Gap Identification**
- Use BallTree nearest-neighbor query: O(m log n)
- Filter population points beyond service radius

**Step 2-3: Hospital-Based Filtering**
- Calculate haversine distance to each hospital: O(m)
- Filter to 30km travel distance (off-road constraint)

**Step 4: DBSCAN Clustering**
- **Density-based spatial clustering**
- Groups nearby gap points into high-density clusters
- Parameters:
  - `eps=5km`: Points within 5km are in same cluster
  - `min_samples=20`: Require at least 20 points to form cluster
  - `metric=haversine`: Great-circle distance on sphere
- **Complexity:** O(m log m) with ball-tree optimization
- **Output:** Cluster labels for each gap point

**Step 5: Centroid Calculation**
- Aggregate by cluster: O(m)
- Calculate mean coordinates (cluster centroid)
- Sum population in each cluster

**Step 6: Greedy Selection**
- Sort clusters by population: O(k log k) where k = # clusters
- Select top 5 (most populous clusters)
- Each becomes a mobile clinic stop

**Step 7: Iterative Planning**
- Remove covered areas for next crew's planning
- Ensures no overlap between mobile clinic routes
- Maximizes total coverage

**Overall Complexity:**
- Per crew: O(m log n + m log m)
- Total: O(cÂ·m log n) where c = # crews

**Key Advantages:**
1. **Hospital-based deployment** - Realistic operational constraint
2. **Density-aware** - DBSCAN finds natural population clusters
3. **Greedy optimization** - Maximizes impact per stop
4. **Non-overlapping** - Iterative removal ensures efficient coverage

### 4.5 Gini Coefficient (Equity Metric)

**Problem:** Measure inequality in healthcare access distribution

**Algorithm:**
```python
def calculate_gini(distances, weights):
    # 1. Sort by distance
    sorted_indices = np.argsort(distances)
    sorted_distances = distances[sorted_indices]
    sorted_weights = weights[sorted_indices]
    
    # 2. Calculate cumulative distribution
    cum_weights = np.cumsum(sorted_weights)
    total_weight = cum_weights[-1]
    cum_weights_norm = cum_weights / total_weight
    
    cum_distances_norm = (np.cumsum(sorted_distances * sorted_weights) / 
                         np.sum(sorted_distances * sorted_weights))
    
    # 3. Calculate Gini using trapezoidal rule (area under Lorenz curve)
    gini = 0.0
    for i in range(1, len(sorted_distances)):
        gini += ((cum_weights_norm[i] - cum_weights_norm[i-1]) * 
                 (cum_distances_norm[i] + cum_distances_norm[i-1]))
    
    return 1 - 2 * gini  # Gini coefficient
```

**Interpretation:**
- **0.0** = Perfect equality (everyone has equal access)
- **0.3-0.5** = Moderate inequality
- **>0.5** = High inequality

**Complexity:** O(m log m) - dominated by sorting

---

## ðŸŽ¨ 5. VISUALIZATION STACK

### 5.1 Frontend Framework: Streamlit

**Technology:** Python-based web framework
```python
import streamlit as st

st.set_page_config(page_title="GAIA Planning", layout="wide")
st.markdown("### Coverage Metrics")

col1, col2, col3 = st.columns(3)
col1.metric("Total Population", f"{total_pop:,.0f}")
col2.metric("Coverage", f"{coverage_pct:.1f}%")
```

**Features Used:**
- **Multi-page apps** (`st.Page`, `st.navigation`)
- **Interactive widgets** (sliders, selectboxes, buttons)
- **Caching** (`@st.cache_data`)
- **Session state** (user interaction persistence)

### 5.2 Mapping: PyDeck (deck.gl)

**Technology:** WebGL-powered geospatial visualization

```python
import pydeck as pdk

layers = [
    # Population density heatmap
    pdk.Layer(
        "ScatterplotLayer",
        data=population_df,
        get_position=["longitude", "latitude"],
        get_radius=100,
        get_color="[255, population_scaled, 50, 150]",
        pickable=True
    ),
    
    # Facilities
    pdk.Layer(
        "ScatterplotLayer",
        data=facilities_df,
        get_position=["longitude", "latitude"],
        get_radius=2000,
        get_color=[220, 20, 60, 220],
        pickable=True
    ),
    
    # District boundaries
    pdk.Layer(
        "GeoJsonLayer",
        data=district_geojson,
        get_fill_color=[58, 90, 52, 50],
        get_line_color=[58, 90, 52, 255],
        pickable=True
    )
]

r = pdk.Deck(layers=layers, initial_view_state=view_state)
st.pydeck_chart(r)
```

**Layer Types Used:**
- **ScatterplotLayer** - Points (facilities, population, clinics)
- **GeoJsonLayer** - Polygons (boundaries, choropleth)
- **Custom shapes** - Hospital icons (cross + rectangle polygons)

**Performance:**
- WebGL-accelerated rendering
- Handles 50K+ points smoothly
- Interactive tooltips and selection

### 5.3 Charts: Altair / Streamlit Native

```python
# Bar chart for distance distribution
distance_dist = df.groupby("distance_bin")["population"].sum()
st.bar_chart(distance_dist)

# Metric cards
st.metric("Coverage", "73.5%", delta="+5.2%")
```

---

## âš¡ 6. PERFORMANCE OPTIMIZATIONS

### 6.1 Algorithmic Optimizations

| Operation | Naive Approach | Optimized Approach | Speedup |
|-----------|---------------|-------------------|---------|
| Nearest neighbor search | O(nÂ·m) brute force | O(m log n) BallTree | 100-1000x |
| District assignment | O(mÂ·n) point-in-polygon | O(m log n) R-tree sjoin | 10-100x |
| Coverage calculation | Pandas iterrows | NumPy vectorization | 10-50x |
| Haversine distance | Python loop | NumPy arrays | 100x |

### 6.2 Caching Strategy

**Three-tier cache:**
1. **Function-level cache** (Streamlit `@cache_data`)
   - Cache expensive computations in memory
   - Invalidate on parameter changes
   
2. **Disk-level cache** (Parquet files)
   - Pre-filtered population data
   - Pre-assigned district labels
   - Survives app restarts
   
3. **Pre-computation** (`prepopulate_cache.py`)
   - Run before deployment
   - Generate all cache files
   - Result: instant app startup

**Example timing:**
- **First run (cold cache):** 10-15 seconds
- **Subsequent runs (warm cache):** <1 second
- **After restart (disk cache):** 1-2 seconds

### 6.3 Data Reduction

**Strategy: Separate computation from visualization**

```python
# FULL dataset for accurate metrics (400K points)
population_full = load_population_data("general")  

metrics = calculate_coverage_metrics(population_full, facilities_df)
# Uses ALL 400K points for accurate totals

# SAMPLED dataset for map rendering (50K points)
population_viz = sample_for_visualization(population_full, 50000)

layers.append(
    pdk.Layer("ScatterplotLayer", data=population_viz, ...)
)
# Only send 50K points to browser
```

**Result:**
- Metrics use full precision (400K points)
- Browser only renders 50K points
- Best of both worlds: accuracy + performance

### 6.4 Chunked Processing

**For very large datasets:**
```python
def compute_coverage(pop_csv, tree, chunksize=200_000):
    covered = 0.0
    total = 0.0
    
    for chunk in pd.read_csv(pop_csv, chunksize=chunksize):
        coords_rad = np.deg2rad(chunk[["latitude", "longitude"]])
        people = chunk["mwi_general_2020"]
        
        dist_rad, _ = tree.query(coords_rad, k=1)
        
        total += people.sum()
        covered += people[dist_rad <= service_radius_rad].sum()
    
    return covered, total
```

**Benefits:**
- Constant memory usage (process 200K rows at a time)
- Can handle arbitrarily large CSV files
- No memory overflow errors

---

## ðŸ“¦ 7. TECHNOLOGY STACK SUMMARY

### Core Stack

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Backend** | Python | 3.8+ | Core logic and algorithms |
| **Web Framework** | Streamlit | 1.51.0 | Interactive web UI |
| **Geospatial** | GeoPandas | 0.14.0+ | Spatial operations |
| **Geometry** | Shapely | 2.1.2 | Geometric manipulations |
| **Data Processing** | Pandas | 2.3.3 | Dataframe operations |
| **Numerical Computing** | NumPy | 2.3.4 | Vectorized math |
| **Machine Learning** | scikit-learn | 1.7.0+ | BallTree, DBSCAN |
| **Mapping** | PyDeck | 0.9.1 | WebGL geospatial viz |
| **File Format** | PyArrow | 21.0.0 | Parquet serialization |

### Supporting Libraries

- **scipy:** Statistical functions (1.16.3)
- **requests:** HTTP client for data download (2.32.5)
- **gdown:** Google Drive downloads (5.2.0)

### Data Formats

- **CSV:** Raw population and facility data
- **Parquet:** Cached/preprocessed data (columnar, compressed)
- **GeoJSON:** Geographic boundaries and shapes
- **JSON:** Configuration and metadata

---

## ðŸŽ¯ 8. KEY INNOVATIONS

### 8.1 Dual-Layer Population Handling
**Problem:** 400K points crash browser  
**Solution:** 
- Use ALL points for metrics (accuracy)
- Sample 50K for visualization (performance)
- Transparent to user

### 8.2 Three-Tier Caching
**Problem:** Slow startup times  
**Solution:**
- Memory cache (runtime)
- Disk cache (across restarts)
- Pre-population (deployment)

### 8.3 R-tree Spatial Indexing
**Problem:** District assignment too slow (5 minutes)  
**Solution:**
- Use GeoPandas R-tree spatial join
- Reduce to 5-30 seconds (10-100x speedup)

### 8.4 Density-Based Clustering for Routing
**Problem:** Where to place mobile clinics?  
**Solution:**
- DBSCAN identifies natural population clusters
- Greedy selection maximizes coverage
- Hospital-based deployment (operationally realistic)

### 8.5 Real-Time Interactive Analysis
**Problem:** Static reports don't support exploration  
**Solution:**
- Streamlit + PyDeck interactive dashboard
- Dynamic filtering (facility type, ownership, status)
- Live metric recalculation
- Clickable legends, tooltips, expandable sections

---

## ðŸ“ˆ 9. SCALABILITY

### Current Scale
- **Population points:** 400K per dataset Ã— 7 datasets = 2.8M points
- **Facilities:** 1,400 facilities
- **Districts:** 28 districts, 200+ sub-districts
- **Response time:** <1 second (with cache)

### Theoretical Limits
- **BallTree:** Can handle millions of points efficiently
- **GeoPandas:** Limited by RAM (~10-20M points on 16GB)
- **Streamlit:** WebSocket limit ~50MB data transfer
- **Browser:** WebGL can render 100K+ points

### Scaling Strategy
- **Horizontal:** Process districts independently (parallelizable)
- **Vertical:** Use Dask for out-of-core processing
- **Cloud:** Deploy on larger instances for bigger datasets

---

## ðŸ† 10. IMPACT METRICS

### Current Coverage (Malawi)
- **Population:** ~19 million
- **Facilities:** 1,400+ functional facilities
- **Coverage (5km radius):** ~60-70% (varies by district)
- **Healthcare deserts:** ~20-30% of population >10km from care

### Mobile Clinic Planning Results
- **Proposed crews:** 10 mobile clinic teams
- **Stops per crew:** 5 weekly stops
- **Additional coverage:** +5-10 percentage points
- **People reached:** ~500K-1M additional people

### Technical Performance
- **Processing speed:** 400K population points in <10 seconds
- **Spatial queries:** 1M distance calculations in ~2 seconds
- **Interactive response:** <1 second for most operations
- **Cache hit rate:** >95% after first load

---

## ðŸ”® 11. FUTURE ENHANCEMENTS

### Algorithmic
- **Multi-objective optimization:** Balance coverage + cost + travel time
- **Temporal analysis:** Seasonal population movements, facility closures
- **Network analysis:** Use road networks for realistic travel times (vs. straight-line)
- **Machine learning:** Predict facility utilization, demand patterns

### Data
- **Real-time integration:** Live facility status updates
- **Patient flow data:** Actual utilization metrics from clinics
- **Health outcomes:** Link coverage to health indicators (mortality, vaccination rates)
- **Satellite imagery:** Use ML to identify settlements, roads

### Visualization
- **3D terrain:** Elevation data for realistic travel distance
- **Animated routes:** Show mobile clinic schedules over time
- **Comparative scenarios:** Side-by-side "before/after" analysis
- **Mobile app:** Field deployment planning tool

---

## ðŸ“š 12. REFERENCES & DATA SOURCES

### Data Sources
1. **Meta Data for Good** - High Resolution Population Density Maps
   - URL: https://data.humdata.org/dataset/malawi-high-resolution-population-density
   - License: Creative Commons Attribution International

2. **Malawi Health Facility Registry (MHFR)**
   - Source: Ministry of Health, Malawi

3. **geoBoundaries**
   - URL: https://www.geoboundaries.org/
   - License: Open Database License (ODbL)

4. **GAIA Mobile Health Clinic**
   - URL: https://www.gaiahealthmalawi.org/
   - Data: Internal GPS logs (provided for hackathon)

### Technical References
- **BallTree Algorithm:** Omohundro, S.M. (1989). "Five Balltree Construction Algorithms"
- **DBSCAN Clustering:** Ester, M., et al. (1996). "A Density-Based Algorithm for Discovering Clusters"
- **Haversine Formula:** Sinnott, R.W. (1984). "Virtues of the Haversine"
- **Gini Coefficient:** Gini, C. (1912). "Variability and Mutability"

### Libraries & Frameworks
- **Streamlit:** https://streamlit.io/
- **GeoPandas:** https://geopandas.org/
- **PyDeck:** https://deckgl.readthedocs.io/
- **scikit-learn:** https://scikit-learn.org/

---

## ðŸŽ¤ 13. PRESENTATION TALKING POINTS

### Opening Hook
> "In rural Malawi, distance equals death. A mother walks 20 kilometers to the nearest clinic. By the time she arrives, it's too late. We built a tool to ensure this never happens again."

### Technical Sophistication
- **400,000 data points** processed in seconds
- **BallTree spatial indexing** - 100x faster than brute force
- **DBSCAN clustering** - ML-driven route optimization
- **Three-tier caching** - Instant app performance

### Real-World Impact
- **Visualize the invisible:** Population density maps reveal hidden communities
- **Quantify inequity:** Gini coefficient shows healthcare access inequality
- **Actionable insights:** Specific GPS coordinates for mobile clinic deployment
- **District-level planning:** Tailored strategies for 28 administrative regions

### Engineering Excellence
- **Separation of concerns:** Computation vs. visualization
- **Scalable architecture:** Handles millions of data points
- **Production-ready:** Cached, optimized, deployable
- **Open source:** Reproducible, extensible, transparent

### Closing Impact
> "This isn't just data visualization. It's a decision support system that can save lives. Every percentage point of coverage increase means thousands of people gaining access to healthcare. That's the power of elegant algorithms applied to real-world problems."

---

## ðŸ“ž Contact & Repository

**GitHub:** https://github.com/dcallega/gaia_planning  
**Team:** GAIA Planning Team  
**Hackathon:** Hack for Social Impact  
**Challenge:** PS7 - GAIA Health Data-Driven Resource Allocation

---

*This technical stack demonstrates the power of combining geospatial algorithms, interactive visualization, and healthcare domain knowledge to solve critical real-world problems. Every technical choiceâ€”from BallTree indexing to DBSCAN clusteringâ€”was made with one goal: making healthcare accessible to everyone in Malawi.*

